
---   
<div align="center">    
 
# MÂ³T: Multi-Modal Multi-Task Learning for Continuous Valence-Arousal Estimation

[![Paper](http://img.shields.io/badge/paper-arxiv.XXXX.YYYY-B31B1B.svg)](https://arxiv.org)
[![Conference Workshop](http://img.shields.io/badge/FG-2020-4b44ce.svg)](https://ibug.doc.ic.ac.uk/resources/affect-recognition-wild-unimulti-modal-analysis-va/) 
[![Challenge](http://img.shields.io/badge/ABAW-2020-4b44ce.svg)](https://ibug.doc.ic.ac.uk/resources/fg-2020-competition-affective-behavior-analysis/)   
</div>
 
## Description   
Valence-arousal estimation models trained on Aff-Wild2.

## How to run   
First, install dependencies   
```bash
# clone project   
git clone https://github.com/sailordiary/affwild2-va-models
```

You can download our cropped-aligned face tracks here: [256x256](https://mailsucaseducn-my.sharepoint.com/:f:/g/personal/zhangyuanhang15_mails_ucas_edu_cn/ErGo36iyXzFFtHcyXIQIuZABnaLsMiHE1CZ5EhsQ7HzhMw?e=9xBNXT)

## Results
Aff-Wild2 Valence-Arousal Estimation Model Zoo:

### Citation   
```
@misc{zhang2020m3t,
    title={$M^3$T: Multi-Modal Continuous Valence-Arousal Estimation in the Wild},
    author={Yuan-Hang Zhang and Rulin Huang and Jiabei Zeng and Shiguang Shan and Xilin Chen},
    year={2020},
    eprint={2002.02957},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
```
